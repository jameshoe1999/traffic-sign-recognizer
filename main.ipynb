{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import common as cm\r\n",
    "\r\n",
    "cm.files_rename('src')\r\n",
    "data, labels = cm.load_data('src')\r\n",
    "print('Size of Data:', len(data))\r\n",
    "print('Size of Label:', len(labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of Data: 4081\n",
      "Size of Label: 4081\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "dataset = [] # dataset\r\n",
    "label = [] # label\r\n",
    "for (index, image) in enumerate(data):\r\n",
    "    result = cm.preprocess_image(image)\r\n",
    "    if (result is None):\r\n",
    "        continue\r\n",
    "    dataset.append(result)\r\n",
    "    label.append(labels[index])\r\n",
    "\r\n",
    "data_size = len(dataset)\r\n",
    "data_type = type(dataset)\r\n",
    "print(f'''\r\n",
    "Data size: {data_size}\r\n",
    "Data type: {data_type}\r\n",
    "''')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Data size: 3890\n",
      "Data type: <class 'list'>\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "import collections\r\n",
    "\r\n",
    "counter = collections.Counter(label)\r\n",
    "counter.most_common()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('80', 1259), ('TC', 989), ('NE', 703), ('SP', 528), ('TK', 300), ('TR', 111)]"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "\r\n",
    "X = np.array(dataset)\r\n",
    "\r\n",
    "print('X shape:', X.shape)\r\n",
    "\r\n",
    "label_set = set(label)\r\n",
    "classes = { val: key for (key, val) in enumerate(label_set)}\r\n",
    "\r\n",
    "print(classes)\r\n",
    "\r\n",
    "Y = np.fromiter([classes[y] for y in label], dtype=np.int)\r\n",
    "Y = to_categorical(Y)\r\n",
    "dense = len(Y[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape: (3890, 512, 256, 1)\n",
      "{'NE': 0, 'TC': 1, 'TK': 2, '80': 3, 'SP': 4, 'TR': 5}\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\r\n",
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3112, 512, 256, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\r\n",
    "\r\n",
    "# initiate model\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "# add model layers\r\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(512, 256, 1)))\r\n",
    "model.add(MaxPool2D((2, 2)))\r\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\r\n",
    "model.add(MaxPool2D((2, 2)))\r\n",
    "model.add(Conv2D(128, (4, 4), activation='relu'))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(dense, activation='softmax'))\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 509, 253, 32)      544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 254, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 251, 123, 64)      32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 61, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 122, 58, 128)      131200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 905728)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 5434374   \n",
      "=================================================================\n",
      "Total params: 5,598,950\n",
      "Trainable params: 5,598,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# compile model using accuracy to measure the performance\r\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# train the model\r\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 290s 3s/step - loss: 0.4663 - accuracy: 0.8332 - val_loss: 0.0885 - val_accuracy: 0.9794\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 287s 3s/step - loss: 0.0640 - accuracy: 0.9836 - val_loss: 0.0352 - val_accuracy: 0.9910\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 285s 3s/step - loss: 0.0228 - accuracy: 0.9939 - val_loss: 0.0512 - val_accuracy: 0.9846\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b9fd1b6310>"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "model.save('saved_models/my_model')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/my_model\\assets\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "22d9742e846c5b2e6352a52abbfdb0eaab0b509899a61abbfb2417673253b584"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}