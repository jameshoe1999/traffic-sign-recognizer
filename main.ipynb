{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Traffic Sign Recognition using Histogram of Oriented Gradient and Convolutional Neural Network\r\n",
    "This notebook will showcase the training process of the traffic sign recognizer using neural network. Before you click Run All, it is important to check that the following packages were installed on your host machine.\r\n",
    "  1. opencv-python\r\n",
    "  2. tensorflow\r\n",
    "  3. numpy\r\n",
    "  4. scikit-image\r\n",
    "  5. scipy\r\n",
    "\r\n",
    "## Move your dataset to the src folder\r\n",
    "Note that you should rename the files of a type as \"XXXX_\" where XXXX is the label of the image,\r\n",
    "the label should not be more than 4 characters!\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Acqusition \r\n",
    "Loading the dataset along with the respective labels\r\n",
    "If the dataset has one __80 speed limit__ sign and another __stop__ sign,\r\n",
    "the labels will be ['80', 'Stop']\r\n",
    "__Note__: The size of data and label should be the same, report to us if you find the size was different."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import common as cm\r\n",
    "\r\n",
    "cm.files_rename('src')\r\n",
    "data, labels = cm.load_data('src')\r\n",
    "print('Size of Data:', len(data))\r\n",
    "print('Size of Label:', len(labels))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Size of Data: 4081\n",
      "Size of Label: 4081\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing Stage\r\n",
    "Every image in the dataset will undergo the preprocessing stage which included the following operations:\r\n",
    "  1. Histogram Normalization - to enhance the constrast and detail of an image\r\n",
    "  2. Hough Transform - to detect the largest circle in the image and return the content within the circle, it was set to accept not so round shape as well.\r\n",
    "  3. HOG feature descriptor - to extract the feature from the images, features as in the change in gradient.\r\n",
    "  4. Reshaping - reshape the image to (*image.shape, 1) for the classifier\r\n",
    "You may notice the data size was reduced to a lower number.\r\n",
    "This is because the preprocessor will filter out those photos in awful quality, or when the Hough transform failed to detect round shape on the image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "from parallel import preprocess_image_parallel as preprocess\r\n",
    "\r\n",
    "dataset, label = preprocess(data, labels) # dataset\r\n",
    "data_size = len(dataset)\r\n",
    "data_type = type(dataset)\r\n",
    "print(f'''\r\n",
    "Data size: {data_size}\r\n",
    "Data type: {data_type}\r\n",
    "''')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Data size: 4081 and data chunk per core: 408\n",
      "\n",
      "Data size: 3889\n",
      "Data type: <class 'numpy.ndarray'>\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code shows the sizes of each type of traffic signs.\r\n",
    "Depending on the traffic signs dataset you downloaded, the sizes of each type of traffic signs can be different.\r\n",
    "The counting was presented as the following format:\r\n",
    "(name_of_sign, size_of_sign)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import collections\r\n",
    "\r\n",
    "counter = collections.Counter(label)\r\n",
    "counter.most_common()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('80', 1258), ('TC', 989), ('NE', 703), ('SP', 528), ('TK', 300), ('TR', 111)]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing Stage 2\r\n",
    "It is required to convert the image dataset to numpy array for the classifier to work with.\r\n",
    "For the label, we first converted them into numeric form ('80' -> 0, 'SP' -> 1, etc.)\r\n",
    "Then, the label was categorized into the CNN preferred format which is:\r\n",
    "say there is 5 types of sign, and the first sign is __80 speed limit sign__ which is the index 0 after the conversion will become\r\n",
    "  [1, 0, 0, 0, 0]\r\n",
    "where the remaining 4 zeros are reserved for the other 4 signs."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from tensorflow.keras.utils import to_categorical\r\n",
    "from json import dumps\r\n",
    "\r\n",
    "X = np.array(dataset)\r\n",
    "\r\n",
    "print('X shape:', X.shape)\r\n",
    "\r\n",
    "label_set = set(label)\r\n",
    "classes = { val: key for (key, val) in enumerate(label_set)}\r\n",
    "# cache the label types for testing purpose\r\n",
    "output_text = dumps(classes)\r\n",
    "output = open('classes.txt', 'w')\r\n",
    "output.write(output_text)\r\n",
    "output.close()\r\n",
    "print(classes)\r\n",
    "\r\n",
    "Y = np.fromiter([classes[y] for y in label], dtype=np.int)\r\n",
    "Y = to_categorical(Y)\r\n",
    "dense = len(Y[0])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "X shape: (3889, 512, 256, 1)\n",
      "{'TR': 0, 'TK': 1, '80': 2, 'TC': 3, 'NE': 4, 'SP': 5}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data splitting\r\n",
    "We need to separate part of the data for testing purpose."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from sklearn.model_selection import train_test_split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\r\n",
    "X_train.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(3111, 512, 256, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Contruct the layers of our CNN model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from tensorflow.keras.models import Sequential\r\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten\r\n",
    "\r\n",
    "# initiate model\r\n",
    "model = Sequential()\r\n",
    "\r\n",
    "# add model layers\r\n",
    "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(256, 256, 1)))\r\n",
    "model.add(MaxPool2D((2, 2)))\r\n",
    "model.add(Conv2D(64, (4, 4), activation='relu'))\r\n",
    "model.add(MaxPool2D((2, 2)))\r\n",
    "model.add(Conv2D(128, (4, 4), activation='relu'))\r\n",
    "model.add(Flatten())\r\n",
    "model.add(Dense(dense, activation='softmax'))\r\n",
    "model.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 509, 253, 32)      544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 254, 126, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 251, 123, 64)      32832     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 125, 61, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 122, 58, 128)      131200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 905728)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 5434374   \n",
      "=================================================================\n",
      "Total params: 5,598,950\n",
      "Trainable params: 5,598,950\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# compile model using accuracy to measure the performance\r\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# train the model\r\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "98/98 [==============================] - 284s 3s/step - loss: 0.6072 - accuracy: 0.7997 - val_loss: 0.1450 - val_accuracy: 0.9576\n",
      "Epoch 2/3\n",
      "98/98 [==============================] - 282s 3s/step - loss: 0.0705 - accuracy: 0.9759 - val_loss: 0.0542 - val_accuracy: 0.9807\n",
      "Epoch 3/3\n",
      "98/98 [==============================] - 281s 3s/step - loss: 0.0230 - accuracy: 0.9945 - val_loss: 0.0258 - val_accuracy: 0.9923\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e444140430>"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Never forget to save the model!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model.save('saved_models/my_model')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: saved_models/my_model\\assets\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Post-training\r\n",
    "Now, let's run some testing with our trained model to disclose the underlying performance in terms of how accurate and precise the model can achieve.\r\n",
    "The measurement included the following score:\r\n",
    "  1. Accuracy\r\n",
    "  2. Precision\r\n",
    "  3. Recall\r\n",
    "  4. F Score\r\n",
    "\r\n",
    "## Let's predict!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "Y_predict = model.predict(X_test)\r\n",
    "# The predicted result tell you how likely the item belongs to each class.\r\n",
    "# In this case, you should look at the highest one\r\n",
    "Y_predict"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.2107743e-12, 9.9996102e-01, 7.1311042e-06, 3.7313619e-06,\n",
       "        2.7994107e-05, 1.8911867e-07],\n",
       "       [5.9810273e-13, 1.9131225e-08, 9.9999809e-01, 1.0206600e-06,\n",
       "        8.1619375e-15, 7.9946363e-07],\n",
       "       [2.2624832e-12, 8.4217919e-12, 8.4528771e-21, 1.7805880e-07,\n",
       "        9.9999988e-01, 5.4051525e-12],\n",
       "       ...,\n",
       "       [9.9994338e-01, 1.1207113e-06, 3.4379937e-05, 4.2873339e-06,\n",
       "        7.5084586e-07, 1.6125881e-05],\n",
       "       [3.7622783e-13, 3.3539950e-14, 4.4315536e-23, 1.2600932e-08,\n",
       "        1.0000000e+00, 7.5525984e-13],\n",
       "       [4.0655745e-09, 1.5037463e-05, 9.9764556e-01, 2.3237057e-03,\n",
       "        3.8136543e-06, 1.1935613e-05]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# the actual labels in Y\r\n",
    "# 1 indicate where the item belongs among the types of signs\r\n",
    "y_test"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "As you can see the output above, both actual and predicted labels for each item is an vector sized of 6 (the number of types we trained our model to recognize) and it is filled with *probability* of how likely the predicted sign belongs to each class.\r\n",
    " \r\n",
    "## But\r\n",
    "Our sklearn.metrics scoring system does not quite understand this kind of format.\r\n",
    "Therefore before we get started, we should reshape our actual and predicted result into a readable format that is easy for our metric examinator to understand."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Let's us map these data into telling us the exact class that it belongs.\r\n",
    "Y_predict_formatted = [np.argmax(y) for y in Y_predict]\r\n",
    "Y_actual_formatted = [np.argmax(y) for y in y_test]\r\n",
    "print(Y_predict_formatted[:5])\r\n",
    "print(Y_actual_formatted[:5])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1, 2, 4, 2, 3]\n",
      "[1, 2, 4, 2, 3]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Which sign each number represent\r\n",
    "# TR: Turn Right\r\n",
    "# TK: Truck (Alert large vehicle approaching)\r\n",
    "# 80: 80 Speed Limit\r\n",
    "# TC: Two cars (No overtaking)\r\n",
    "# NE: No entry\r\n",
    "# SP: Stop \r\n",
    "print(classes)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'TR': 0, 'TK': 1, '80': 2, 'TC': 3, 'NE': 4, 'SP': 5}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\r\n",
    "\r\n",
    "classification_result = classification_report(Y_actual_formatted, Y_predict_formatted)\r\n",
    "print(classification_result)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97        17\n",
      "           1       0.96      1.00      0.98        64\n",
      "           2       0.99      0.98      0.99       252\n",
      "           3       1.00      1.00      1.00       215\n",
      "           4       1.00      1.00      1.00       146\n",
      "           5       1.00      0.98      0.99        84\n",
      "\n",
      "    accuracy                           0.99       778\n",
      "   macro avg       0.98      0.99      0.99       778\n",
      "weighted avg       0.99      0.99      0.99       778\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "confusion_result = confusion_matrix(Y_actual_formatted, Y_predict_formatted)\r\n",
    "print(f'''\r\n",
    "Confusion Matrix\r\n",
    "{confusion_result}\r\n",
    "''')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "Heavy Vehicle\t:[ 0 64  0  0  0  0]\n",
      "Turn Right\t:[17  0  0  0  0  0]\n",
      "Speed Limit\t:[  1   3 248   0   0   0]\n",
      "No Overtaking\t:[  0   0   0 215   0   0]\n",
      "No Entry\t:[  0   0   0   0 146   0]\n",
      "Stop\t\t:[ 0  0  2  0  0 82]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Voila\r\n",
    "The trained model produced a super-duper suprisingly accurate performance, although we do not know whether there exists an overfitting problem.\r\n",
    "As far as we concern, the model can accurately recognize the known traffic signs from the Google Image."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "# test with a random image downloaded from Google Image\r\n",
    "# It is a stop sign, hence we expect the predict answer to be 5\r\n",
    "test_img = cm.read_image('a-stop-sign.jpg')\r\n",
    "test_img = cm.preprocess_image(test_img)\r\n",
    "if test_img is not None:\r\n",
    "    predict_data = np.array([test_img])\r\n",
    "    prediction = model.predict(predict_data)\r\n",
    "    answer = np.argmax(prediction)\r\n",
    "    if answer == 5:\r\n",
    "        print('The model recognized the sign as Stop sign!!!')\r\n",
    "    else:\r\n",
    "        print('The model failed to recognize the stop sign :\\'(')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The model recognized the sign as Stop sign!!!\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "22d9742e846c5b2e6352a52abbfdb0eaab0b509899a61abbfb2417673253b584"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}